

##### 2024年4月23日22:55:45

终于啊！！！我把gdb的调试用clion搞定了，以后不用控制台调试了：

![132486cff8c3a6e7aafc3d8b2db7e20](C:\Users\Oniar_Pie\Documents\WeChat Files\wxid_cdwianqvldaq22\FileStorage\Temp\132486cff8c3a6e7aafc3d8b2db7e20.png)

但是还有一个问题就是，好像一次只能加载一个symbol-file，加载第二个就会出现“the address where the symbol-file has been loaded is missing”

这个问题还没解决。

之后又大概了解了一下cmake。主要还是用makefile编译，cmake是用来让IDE识别源文件的关系，这样我ctrl+左键就可以自动跳转什么的。

2024年4月26日19:15:04

今天学习了下windows和linux的进程分页是怎么搞的，感觉大受启发，害，我怎么还是没有养成先学习再写的习惯。

在内核中，有一个vmalloc区，用来存储进程的页表，这样不管什么cr3内核都可以访问到页表了，至于页目录放到pcb里面去。

申请新页一般采用page fault，访问没申请的内存然后触发中断申请。

![image-20240426193251393](C:\Users\Oniar_Pie\AppData\Roaming\Typora\typora-user-images\image-20240426193251393.png)

在i386 CPU

将一个线性地址映射为物理地址的过程中,如果该地址的映射已经建立,但是发现相应的页面表项或目录项中的P(Present)标志为0,则表明相应的物理

页面不在内存.此时,CPU**将错误的请求地址放在寄存器CR2中**,并发生缺页中断.

2024年4月26日21:30:30

进程跳转到一个奇怪的地址0xe05b

2024年4月26日23:44:42

解决奇怪跳转，是我的PDE没设置好。

但是出现新问题：读段时，readfile导致直接断电重启。初步怀疑是page fault什么没设置好导致第二次调用出问题，但是感觉不是，因为第二次读取是0x400200,没有新页。

2024年4月27日10:16:03

bug修好了，是因为直接用了req_a_page返回的是i*32+j而不是物理地址。

成功写完了pe文件加载的一般过程，通过page fault进行分配页面简便多了。

成功了！！！

改用通过缺页终端分配页面不知道简便了多少倍，真是太感慨了。

现在我可以说，gms os的exe文件加载基本功能已经完成了。

经检验，重定位成功，加载导入表成功，dll的加载还没试过。

**下一步计划**

把进程的分段内存设置好

建立虚拟文件系统，读取扇区通过系统中断调用驱动进行。

写建立堆段的代码。

加入键盘设备和驱动。

写一个shell.exe，用于控制台交互，负责VGA内存控制等。

2024年4月27日16:20:11

进入用户态实现了，但是这个时候时钟中断好像没权限out？

2024年4月27日17:20:18

bug修复，是tss没加载的问题。

tss里面用了DPL=3的描述符后push会page err

2024年4月27日22:14:57

新问题：

dll文件需要lib文件才能链接，这个过程比较麻烦。

2024年4月27日22:39:56

开始了shell的编写，但是遇到了很多困难：

莫名其妙读取exe的时候代码段开头一个字节没读变成0；

内核的syscall switch好像有点问题；

注册驱动结果要注册方设置flag；

想了想还是感觉monitor的驱动写到sysdll里面比较方便，但是这样有一个问题就是这样就需要之前说到的dll和lib文件问题了，需要再单独解决。

**22:50:06**

我想了想，想到一个解决方案：

把sysdll本身各个模块做成驱动，然后函数直接通过注册驱动来传递地址，然后函数对应的编号设置在头文件里让shell引用，就能正确地调用函数。

这样的话，驱动结构体本身要改一下：

```c
typedef struct{
    //...
    int *funk_thunk;
}driver;
```

原来的很多预设操作改成一个指针func_thunk，指向一页vmalloc内存，里面存储一个数组，每项就是函数地址。

**23:37:26**

成功。

##### **2024年4月29日15:18:43**

今天试着写了一下用户库文件，结果发现很操蛋的事。

linux编译不了exe，windows下gcc好像识别不了.a静态库文件，导致我的库没法用windows编译，

然后用linux编译出来还是elf不是pe文件……

看来必须统一一下标准了。

**15:24:44**

没事了，是我傻了，windows下没加-fno-leading-underscore导致找不到符号。

.a文件格式两个系统下是一样的。



现在出现了两个矛盾的事情：
一方面，我想让用户程序直接用dll的方式调用sys.dll，另一方面，现在实际上用的方法是通过系统中断调用sys.dll里面的关键函数，导致我现在有些函数得在静态库再套一层壳。

我想的是，系统库函数只用动态库和配套生成的lib就好了，不应该再写静态库的。

sys.dll里面的函数应该分成这几个部分：

驱动函数。就是驱动的一部分，不提供给用户，需要用系统中断调用。

接口函数。提供给用户的，用dll方法就可以调用。

**16:40:40**

好了，我把dll生成lib的过程自动化了，好多了。

那么，这样的话，就可以把静态库试着取消。

接下来要弄出一个目录专门放用户头文件。



sysdll的驱动总体架构如下：
驱动除了实际处理的函数，还要自己提供一套用户接口函数。

**18:07:22**

shell.exe开始实际用上sys.dll的函数了，但是发现导入表部分代码有bug，改了。

现在可以正常调用sysdll函数！

![image-20240429180814338](C:\Users\Oniar_Pie\AppData\Roaming\Typora\typora-user-images\image-20240429180814338.png)



**22:39:28**

这里把驱动和设备管理大致讲一遍。

二者都要向内核申请注册，至于驱动的中断处理程序问题，可以在驱动和drv_funcs数组中取一个特殊位置，

然后中断向量号也包含在驱动结构体里面，这样内核就能注册中断处理程序。

比如硬盘设备、驱动：



和fat16文件系统驱动：

一块硬盘对应一个文件系统，每一个硬盘，就加载一个文件系统驱动对应，这些不同的文件系统都被管理在内核的虚拟文件系统之下。

比如floppy.img，注册了硬盘设备和驱动之后，就再加载一个fat16驱动，……

啊啊啊，好难想。

主要是，我不知道怎么实现让用户从设备中选一个已有的设备进行读写。比如我现在有好几个硬盘挂载，如果按照windows的方法，那绝对路径就需要一个开头选择硬盘的过程，然后这样的话硬盘盘符需要单独一个数据结构存储，每个盘符里面存储对应的硬盘驱动和文件系统驱动，这样提前选好设备和驱动，才能正确读写。

这样子好像是可以的。这样的好处是不用写新的文件系统。

另一种是用linux的方法，统一到一个文件树下，这样就要写新的文件系统，但是比较好理解。

目前还是选前者吧。

困难的主要原因在于我把文件系统从内核拆出去了，这样不方便，内核还是需要一个虚拟文件系统。

这个文件系统有两种形式：

1.windows形式，其实不能算是文件系统。它只是存储硬盘挂载盘符，然后找到对应的子文件系统。

2.linux形式，这样的话虚拟文件系统就需要完整的形式了，superblock，rootdir等等。

还是倾向前者。

懂了，我现在需要一个存储盘符的数据结构。

那么，如果一个新的硬盘插入了，怎么构建？

首先，触发硬件中断，内核检测到有几个端口有用了，于是注册新设备，然后用已有的驱动一个个尝试打开（open(device*),device里面记录了是哪几个端口），成功的那个就说明是对应的驱动，驱动就会标识dev的类型，把自己连接dev（dev.drvi=self_drvi;），然后长存于内存中。

成功之后，盘符结构会记录对应dev*，这样下次就直接用。



盘符只是一个数据结构，将数据结构用起来的，是虚拟文件系统。

虚拟文件系统的对象主要是文件，面对的是不同设备的文件。

由于采用了windows的结构，虚拟文件系统不能对非文件操作，也没有设备文件，内存文件的概念。

vfs有以下行为：

open

read

write

seek

close

文件路径规定为以下形式：

C:/a.txt

打开文件是一个占有行为，在被打开文件列表中记录下被打开的文件，文件的entry结构要能记录属于哪个盘符，文件的id（这里我私自利用起来fat16entry里面空着的10字节），同时记录pid。

**还是得把vfs从sysdll搬到kernel里面！！！**

##### **2024年5月1日00:03:13**

文件打开的流程（user）：

path->找到文件->返回entry->调用内核虚拟文件系统open

**怎么判断打开的文件已经存在于打开文件列表**

首先不能使用文件路径。文件路径长度不定，给结构体定义带来极大困难。

文件描述符也没法用，因为文件描述符只能说现有的打开文件的编号，同样的文件，第二次打开是还没分配文件描述符的，没法比较。

最后，唯一的办法就是：同一个文件系统，而且文件id一样。

就是，一个文件系统里，每个文件有一个唯一的编号，子文件系统返回给vfs的vfs文件结构体中要包含这个唯一的id，方便vfs判断。

这样就只能牺牲fat16同志啦，fat16没有给每个文件分配唯一编号~

或者我魔改一下也可以。

至于设备选择问题，我还是决定付诸卷管理-这些决定整合到vfs里面，不分化了。

##### **2024年5月1日09:06:53**

今日任务：

把fat16的代码改成适合vfs接口的。

**16:28:19**

新决议：驱动要放到内核空间。

**19:18:03**

把fat16的函数接口改成了驱动样子，虚拟文件系统也写好了。

之前我把内核的功能拿走太多了，现在有些要拿回来。

比如：

虚拟文件系统。

还有一个就是运行文件，运行文件的话，应该是用户系统调用的，这样的话内核是最清楚进程的cwd和所用的文件（entry），但是问题是页表怎么切换？

一个办法，内核先注册进程，函数入口指向内核的统一进程开始函数，然后到进程调度到这里再开始读取，开始文件的读取，这样的话，pe文件格式数据结构就必须重新包含到内核里面去，然后入栈，然后跳转入口。

##### **2024年5月3日12:42:14**

又被windows下gccld编译搞到高血压了……下划线这种b事真烦人。

我要考虑转换到elf和so格式了，现在在windows和linux两种环境下编译真的很多麻烦。

**21:26:34**

我又改变主意了，不用改。

我发现linux可以编译exe。

但是dll编译还是有一大堆问题。

**21:40**

可以了。

**23:28**

tmd血压高了。

为什么fat16突然就读不出来数据了？！读根目录全是0？！

我累了，我他妈的。

再不行，就把fat16重新安回内核，作为默认驱动。

**2024年5月4日11:17:48**

发现问题：计算出来根目录在183号扇区，但是实际上存在了153号扇区？？

是因为根目录不能用clu_sec_balance表示，到别处了。

以前的代码是对的，但是我把他改了。。。

**23:15**

怎么任务切换又出问题了！！！！

**5.5 11:02**

找不到问题所在……

**11:25**

修好了，是我把以前对的代码乱改，改错了设置页表的部分……

**20:27**

我决定接下来先把原有的功能完善，尤其是进程。

要实现进程调用、进程通信、进程的堆空间设置（malloc、free）。

##### **2024年5月11日16:10:02**

进程的内存空间设定如下：

| 地址       | 名称     | 作用 |
| ---------- | -------- | ---- |
| 0-0x100000 | 内核空间 |      |
|            |          |      |
|            |          |      |
|            |          |      |
|            |          |      |
|            |          |      |
|            |          |      |

![image-20240511161453655](C:\Users\Oniar_Pie\AppData\Roaming\Typora\typora-user-images\image-20240511161453655.png)

**17:26**

写好了进程的堆的设置之后，开始写vfs的管道文件。

这需要先把vfs的缓存功能写出来。

vfs的缓存要存储管道文件和常用文件的entry。

缓存结构如下：

1.opened：打开的文件。

2.fifo：管道文件（内存文件）

3.fixed:一直持有的（根目录下的几个文件夹）

4.quicklook：最近访问的。

**sys_mkfifo**

在fifo列表中添加文件，申请内存并映射。

这要求fifo的entry记录文件名以及记录文件夹树关系。

现在这个函数会把fifo文件创建到固定的位置：/procs

参数里面的路径只能有文件名，然后创建的entry的parent指向procs的entry（在fixed中）

（这里有个问题，如果quicklook里面也有procs，这个entry就没有fifo作为子文件了）

**20:25:12**

管道先不做了，这个优先级不是最高的。

接下来写键盘驱动。

关于静态驱动，也是需要注册驱动列表，尽量不要添加到系统调用里面去。

现在已经有了tty设备，那么用户程序怎么使用呢？

stdout的话，也是一个设备，驱动就使用tty的，这样有一个固定的名字。

**21:48**

写好了，现在可以通过设备名字对设备操作了。

这才成功，毕竟对于用户来说只知道名字，不知道devn；

他们也只需要对“设备”操作不需要“调用”驱动。

这样的话，反而原来的以驱动号为索引的操作好像就可以取消了……先不删。

##### **2024年5月12日22:35:34**

初步把用户库写了一点，写了vfs和设备、驱动操作的内容。

标准库的函数之后慢慢写（笑）

好了！我的内核现在初具雏形了！

已经可以配备相应的程序了！

发现问题：loadpe的读段好像有问题

## 2024年5月26日

##### 发现的关于FAT16不能正确读取文件的bug

发现：idata在FOA 0x1a00的位置，整个文件32300kb，应当有45个扇区，但是怎么好像5个扇区后FAT表里面就结尾了？

FAT记录：

225，302，47,48,49，-1。

对应LBA：

408，485，230,231,232

对应偏移：

33000，3ca00,1cc00,1ce00,1d000

实际程序长5b00

存储长a00（？？）

发现1cc00的数据和实际程序400位置处不一样，

发现从1cc00之后的数据根本不是源程序的数据，源数据丢失？？

新firstclunum:347

FOA：2b6+FAT

发现内存中fat和实际fat不一样，第一个扇区之后的内容就不一样了

发现是fat16传参的时候每次读一个扇区没有把lba+1……

修正代码后问题解决！

##### 关于王子给的计算器程序运行时的问题

王子的程序里有浮点数，结果报错coprocessor_notexist，浮点处理器不能用，所以只好去掉这个功能。

##### 结果

终于！能跑别人的程序了！！！

### 之后的打算

#### 1.协处理器

协处理器现在没开启，所以不能浮点运算。之后可以考虑这个。优先度低。

#### 2.shell

交互界面。需要系统库先写好。

#### 3.系统库完善

优先度第一。尤其是获取输入，比如getch,gets这种。

## 2024年5月27日

把库函数puts gets实现了。

但是发现键盘中断没反应。

准备先不管这个问题，先写模块动态加载。

## 2024年5月31日

成功了！！！！！！！！！！！！！！！！！！！！！！！！！！！！

成功地使用grub引导启动我的操作系统！！！而且是elf格式！！！！！

而且，也成功地用vscode可视化调试gdb+qemu内核！！！！！

哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈！！！！！

昨天快搞疯了！！！！

![image-20240531223804117](D:\Coding\OS\qemu\image-20240531223804117.png)

![image-20240531224357152](D:\Coding\OS\qemu\image-20240531224357152.png)

**2024年6月1日**

今天把内核的剩下代码基本搬过来了。

而且成功读取了multiboot2的boot信息！！！！！

然后接下来计划：

1.读取gdtr

2.优化“设备-驱动”数据结构，把记录端口的功能加进去。（最好是只要设备这个数据结构）

**6月2日**

决定优化设备管理结构：

设备号分成主设备号和从设备号。

设备的标识以设备号为主

我发现我现在的文件系统结构和linux有所不同：

![VFS结构](D:\Code\Comprehensive\OS\workspace\doc\VFS结构.png)

**2024年6月8日**

设计了一下文件读写操作：

读取：创建缓冲区，将数据读到缓冲区，然后拷贝到用户区，释放缓冲区。

写入同理。



好累啊……先不写了……

**2024年6月9日**

vfs基本部分写好了，但是由于idt部分没有更改适应grub，导致现在代码不能正常运行……

之后再说，也许期末考之后。

**2024年6月10日**

关于页表管理

表示全部的4G内存需要0x401000大小的内存，但是只表示最低1G的空间只需要0x40100大小。

在目前内核空间定为低端1G的情况下，只需要表示内核空间的全局页表就可以了。

把页目录放在0xa0000，那么上达0xe0100。

好吧这里写不了，好像是rom。

idt是0，gdt是0x800，就从0x1000开始。

算错了：

表示1G内存，页表占0x100000(1M),页目录占0x400

**2024年6月28日**

尝试使用PDE的 4MB存储模式减小页表占用空间

失败，可能qemu不支持，网上搜到的内存分页没有使用这个模式的，感觉还是不建议使用这个。

表示低1G空间需要0x101000内存，放在低地址空间会覆盖VGA缓冲。

那就从高地址开始，从0x100000开始储存，内核从0x201000开始。

运作有错，超出了计算的范围。

以后存东西尽量都不要放在1M以内好了。

已修复。

把gdt调回了0x800

发现发送异步硬盘请求之后，代码会跳转到一个未知的但是有代码的地方，可能是bios。

发现在发出硬盘命令后就跳转了。

下午

发现我的GDT居然设置错了，是16位……段寄存器里面也是错误的值……

修复好之后，硬盘中断正常运行！

现在的新问题是，devman的请求不能执行，一直等待。	

查出原因：块设备和硬盘各自有一层独立的请求队列，沟通机制不完善。

**2024年6月30日**

把设备管理的整个架构大改了，现在看起来顺眼多了，但是还有问题。

bread之后那个读请求卡死了。

**2024年7月6日**

发现硬盘发什么指令，状态码都是0xff,好像出问题了。

发现错误码0xff=

**2024年7月7日**

发现，虽然错误码是ff，但是并不影响读取，就不管了。

发现读取卡死的原因是没有把devman的reqstat改成done。

到目前为止，可以正常运作，但是……

为什么img文件里面DPT是空的？！

发现好像不知道为什么就是空的，然后用fdisk重新创建一下，结果boot没了……

才发现我一开始就没配置好grub，后来能成是因为阴差阳错成了

但是OVFM真的，我找到的成品都不行，要编译的一大堆错误。

我还是再找一个内核加载器吧……

算了，还是用grub。

**17点50分**

不论用什么方法，同样的方式再做一遍，MBR区域就是空的，qemu就是跑不了。

**2024年7月9日**

查了下，还是要弄OVMF，查了下教程，下载VS2019，看看能不能行

**13点10分**

成功了！！！！！！！！！

原来下的现成品是可以用的，只是要在bios里面设置一下启动文件就可以了！！！！

现在开始编写64位内核。

如果映射低32MB空间，则大小0x200 0000。

64位采用四级页表：
PTE：4KB

PDE：2MB

PDPTE:1GB

PML4:512GB

PDE可以采用2MB页，PDPTE可以采用1GB页。

现在映射2GB空间，低1GB归内核，由一个1GB页映射，高1GB归用户，由4MB页映射。

内核初始化的时候必须把内核页映射好。

PML只需要一项就够，PDPTE需要一项1GB页和一项指向PD的一项。

给PD预留一页内存，只会使用其中的256项，足够了。PTE不需要。

综上，总共需要3页内存即0x3000内存。

不使用低0x10 0000内存，则占内存到0x10 3000。

在英特尔手册里面，IA32E模式M=48（最大48位地址）

**20点37分**

之前的GDT设置有问题，现在修复了，怪不得一设置段寄存器就崩溃

**21点03分**

批判我看的教程！！！

《第二章 内核，启动！ - 从零开始开发UEFI引导的64位操作系统内核》

指向BIOS的野指针是作者。

他写的64位长跳转代码是错的！！

![image-20240709210506895](D:\Code\Comprehensive\OS\workspace\doc\image-20240709210506895.png)

这里的jmp我按照他的写，qemu里面显示(bad)，不能执行。

后来查资料发现，jmp的这种写法只能用于32位及以下，其对应的机器码0xea，64位是不能识别的。

应该要用jmp rax的代码，机器码为FF E0。这个才对。

可恶的教程，写了错的代码不检查的吗！！！！没放进去跑过的吗！！！！

**23点11分**

设计了一下内存分页的新框架：

<img src="D:\Code\Comprehensive\OS\workspace\doc\内存分页处理模型.jpg" style="zoom:67%;" />

**2024年9月23日**

**22点05分**

闲时思考了一下，认为之前试图在现阶段把内核和系统的功能拆分不好。

现在内核进程管理和文件系统都不稳定，最方便最有效率的开发方式仍然是把内容集中到内核一个文件中去。

那么之后就和内核写到一块去。等到之后图形化界面和文件系统这些成熟之后，再考虑拆分，不然大把的时间都要花在两个分离模块之间的通信上。

很久没看代码了，日志起了很大回忆作用。接下来的任务我认为还是在内核的初始化阶段，包括页帧缓存的管理，绘图函数，任务切换的方式改变等。

虽然说是集中到一个文件里面去，实际上是指编译到一个elf文件里面；里面每个模块之间的分工依旧必须是分明的。之前写的c文件头文件引用格式似乎不太规范，经常出现redefinition这样的错误，之后也要好好梳理一下代码。

**2024年9月25日 17点11分**

检查了一下代码：

1. 代码在之前就已经合并好了，现在就是编译成一个内核文件
2. 考虑到clion功能更完善，gdb调试比vscode好（vscode有时候没法函数溯源到正确的源文件），改用了clion
3. 很多代码还没适应64位，比如传参需要传函数地址的时候，参数还没从32位改成64位
4. 很多代码还没适应调整后的显示缓存，比如很多文件里面的printf还没去掉

代码目前是一运行printf就死掉了……

之后有时间开始修理修理。

**18点33分**

为了防止之后长时间没看重拾的时候使用有困难，在此记录编译，拷贝和调试方法：

编译：

make com

make knl

拷贝：

make cpknln

运行:

make debug

gdb.sh

使用控制台运行。如果cpknln出现问题，可以手动执行里面的命令。

**19点22分**

发现到main函数的时候，之前传的参已经被压到栈里面很深了，取参数的时候取不到。

发现入栈的时候仍然是以32位入栈，而参数类型采用了long,可能是这个原因。

**20点55分**

发现不是。是因为在64位条件下，传参默认首先从寄存器传递。

将setup中的push改为设置寄存器后，bug修复。

发现似乎从unsigned int到结构体指针转换有问题。

怎么从赋值到指针的时候值会自己减一？？？

以后写地址的时候要注意后面加L,不然不是long类型

**21点39分**

发现一个比较严重的问题。

gcc自己编译出来的代码怎么好像没法完全复制64位变量？

给64位变量赋值只能覆盖前32位？

怀疑编译步骤出现问题。

**21：57**

没问题。更换堆栈到1M之外的区域之后就可以完全覆盖64位了。

看来是因为原来设置在1e00可能和有特殊用途的内存重叠了。

但是指针转换后仍然会自动-1。

**2024年9月26日 17点36分**

查看gdb发现，刚赋值给rax的时候是0x1e000，是之后被减一的。

反汇编出来的代码和实际运行有差别。

查了下，grub引导完是保护模式，我没有按照规范在进入64位之前设置好页表。

可能是这个原因？

**20点33分**

不是这个原因。

**20点56分**

发现堆栈异常行为：

rsp:0x400000, after push: 0x40fffc

????

而且后面的关于指针的加减法全都是错的……

**2024年9月27日**

**16点41分**

成功！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！

原来是因为我前面就没有进入64位模式，还是32位！！！！

之前我少了个步骤所以才不能按照教程上的代码跳转：

```nasm
; 打开PAE
    mov eax, cr4
    bts eax, 5
    mov cr4, eax
```

教程的跳转：

```nasm
jmp dword 0x8:main
```

现在可以了

原来是我错怪了教程……

现在不会有奇怪的指针计算错误了！！！！

**18点03分**

framebuffer_pitch的意思是，两个相邻行的同列像素之间的字节间隔。

这个教程又讲错了……好你个野指针……

<img src="D:\Code\Comprehensive\OS\workspace\doc\image-20240927195334304.png" alt="image-20240927195334304" style="zoom:50%;" />

**19点53分**

成功实现了屏幕绘制功能。

接下来准备搞文字绘制。这次从网上直接下过来psf字体打包到elf里面。

**21点49分**

实现了字体绘制，而且是别人的字体。

通过objcopy打包进elf文件，来引用psf字体文件

<img src="D:\Code\Comprehensive\OS\workspace\doc\image-20240927215013194.png" alt="image-20240927215013194" style="zoom:50%;" />

**22点22分**

实现更完美的文字输出了。

目前的问题是init_int.

**2024年9月28日**

原来32位的汇编代码现在在64位下有很多问题。

首先就是pusha不能用了。

看了下:

>  You can assume that the C compiler will generate code that will be preserving `rbx`, `rbp`, `rsi`, `rdi`, and `r12` thru `r15`. You should only need to save and restore `rax`, `rcx`, `rdx`, and `r8` thru `r11`. *(Note: on Linux or other System V ABI platforms, the compiler will be preserving `rbx`, `rbp`, `r12`-`r15`, you can expect `rsi` and `rdi` clobbered)*.

所以即使不用pusha，我也只需要push部分寄存器就可以了。

其次是push只能push八个字节的内容，只能push r开头的寄存器

**10点49分**

中断又出现以前的问题：莫名跳转，随机性

**16点40分**

我觉得是idt，gdt内存没有对齐。

通过使用lds，来强制对齐。

**17点01分**

对其之后，仍然会在某一步骤后跳到general_protect

可能是我的代码有问题？

但是general protect之前堆栈显示跳转前代码处于的位置那个函数里面就没有代码，哪来的代码有问题

恐怕还是中断设置有问题。

关闭时钟中断还是会这样，说明不是时钟中断的问题。

**2024年9月29日**

**16点36分**

调换了下函数调用顺序还是这样，说明应该不是我代码里面的问题，应该就是idt设置问题。

但是general protect又可以成功跳转！

**17点32分**

把general protect的死循环去掉之后，发现似乎问题出现在frambuffer的绘制上。

**18点32分**

不是的……好像是调用函数的时候就出现问题了……但是我汇编一句一句执行又不会有问题……随机性好大……

目前没找到办法，先把中断关掉好了。

**19点05分**

解决了。

查了很久查到一个资料：

> ### Trap Gate
>
> A **Trap Gate** should be used to handle **[Exceptions](https://wiki.osdev.org/Exceptions)**. 
>
> [Interrupt Descriptor Table - OSDev Wiki](https://wiki.osdev.org/Interrupt_Descriptor_Table#Structure_on_x86-64)

看了下自己的代码发现自己的异常分配的是int gate而不是trap gate，改了过来，结果就好了！！！！！！！！！？？

64位对这个有要求的吗？？？？之前写32位的时候是反过来的，异常用int gate，中断用trap gate，从没出现过这个问题

**2024年10月1日**

**11点01分**

简单列一下接下来的计划：

1. 完善键盘中断
2. 完善进程管理，还是继续用TSS吧，方便一点
3. 实现应用层，可以在内核内部临时写一个函数充当一下应用层函数
4. 完善文件系统，将自己的VFS趋向POSIX标准

这样之后，设备管理的问题也会顺带解决。POSIX标准的虚拟文件系统已经有很多人写过了，所以参考起来开发就方便得多。

**2024年10月3日**

今天改了下内存管理，把原来写了没用到的内存区域管理用上了。

简单说就是，把multiboot2里面记录的不同区域的内存类型给记录了下来，然后根据内存大小动态设置了物理分页位图，放在了内核之后。目前还是以4KB页为单位，但是之后会考虑用2MB页的。

然后把键盘中断的内容改成了简单地把扫描码放到缓冲区中。

然后开始着手任务切换，intel手册原文：

> The operating system must create at least one 64-bit TSS after activating IA-32e mode. It must execute the LTR instruction (in 64-bit mode) to load the TR register with a pointer to the 64-bit TSS responsible for both 64-bit mode programs and compatibility-mode programs.

64位的TSS格式很不一样了，只记录了RSP,IST和IO位图。



实现了64位下的进程切换，但是好像切换了一次后就没出发时钟中断了

**2024年10月4日**

今天尝试切换到ring 3，到目前为止都失败了。

iret：general protection

sysexit：invalid opcode

> When SYSRET transfers control to 64-bit mode user code using REX.W, the processor gets the privilege level 3 
>
> target code segment, instruction pointer, stack segment, and flags as follows:
>
> • **Target code segment** — Reads a non-NULL selector from IA32_STAR[63:48] + 16.
>
> • **Target instruction pointer** — Copies the value in RCX into RIP.
>
> • **Stack segment** — IA32_STAR[63:48] + 8.
>
> • **EFLAGS** — Loaded from R11.

终于！！sysret成功了！！！

使用sysret，成功将cs的特权级转换到ring 3。虽然不知道为什么选择子还是0x10(+3)没有变成0x28

知道了，是应为wrmsr的高32位在edx。

终于！！！！！！！！！！

看起来，sysexit没有sysret那么广泛被使用啊。

**2024年10月5日**

今天着手vfs和fat32。

但是这块确实很复杂，代码量也很大，所以我现在直接把代码从别人那里搬了过来

《一个64位操作系统的设计与实现》从这里搬过来的。

稍微调整了一下就整合进去了。

然后是syscall：

> For SYSCALL, the processor saves RFLAGS into R11 and the RIP of the next instruction into RCX; it then gets the privilege-level 0 target code segment, instruction pointer, stack segment, and flags as follows:
>
> • **Target code segment** — Reads a non-NULL selector from IA32_STAR[47:32].
>
> • **Target instruction pointer** — Reads a 64-bit address from IA32_LSTAR. (The WRMSR instruction ensures that the value of the IA32_LSTAR MSR is canonical.)
>
> • **Stack segment** — Computed by adding 8 to the value in IA32_STAR[47:32].
>
> • **Flags** — The processor sets RFLAGS to the logical-AND of its current value with the complement of the value in the IA32_FMASK MSR.

完成了系统调用的功能部分，包括切换堆栈。

突然出现新bug，print会卡住，里面的一些参数被篡改。

怀疑是某处的代码没有进行栈平衡。

发现在出错的时候，原来的print的y值总是被设置成0x7fffffff。

感觉就是某处bug。

之后计划做POSIX标准接口函数的文件操作部分。

感觉为了快速开发，很多代码也可以直接借鉴。

毕竟自己再从0重新开发实在是耗时间。

**2024年10月6日**

发现，print出错的时候，draw_letter的y值被设置成了和rsp一样的值

好像发现原因了：

gcc把参数放到堆栈rsp更低的空间，一旦中途出现中断，中断就直接入栈一堆信息把原来参数那片地方直接覆盖掉了……

看来要在中断发生的时候切换堆栈啊

不对啊，这也没用啊，中断发生的时候是直接入栈数据的来不及切换堆栈。

查阅了下资料，发现还是有办法的：

> In IA-32e mode, a new interrupt stack table (IST) mechanism is available as an alternative to the modified legacy stack-switching mechanism described above. This mechanism unconditionally switches stacks when it is enabled. It can be enabled on an individual interrupt-vector basis using a field in the IDT entry. This means that some interrupt vectors can use the modified legacy mechanism and others can use the IST mechanism. 

也就是说设置了IST就可以避免上述情况。

成功！！！！！

设置了IST之后，中断入站的数据就在新的堆栈空间里面了，不会污染原来的数据了！！

接下来把其他模块里面的vfs改过来就可以开始着手系统调用API改造了！

**2024年10月7日**

通过快速借鉴别人的文件操作部分的POSIX函数接口实现，很快地完成了这部分。

嗨呀……这部分借鉴没什么好说的呀，这部分谁写都差不多吧？要完成的功能差不多的话，就算是我自己写，最后出来的代码也差不多吧？那还是效率高的好。

也是稍微改了下就整合进去了。

之后随着系统升级，这部分代码也会渐渐被改得越来越不像借鉴来的吧……

到这里，《64位》这本书也差不多到结尾了，之后的内容又是我一个人前行。（虽然中间很多内容没做，比如多处理器这种，目前没必要吧）

之后就是把剩下的代码继续跟上64位，比如原来的execute函数就还没改，还是32位的样子。

先着手从execute这个功能开始吧，然后进程管理的很多函数也要优化。

运行exe文件的函数，exe数据结构定义得大改呢。

没想到的是其实工作量很小……



接下来计划让设备驱动标准化，也就是让他们符合POSIX接口，具有read等，尤其是键盘，让键盘的缓冲区能以文件的形式被读取。

目前还有一个比较关键的bug，就是进程调度过一次后就没法再调度了。



修好了。
接下来需要把进程切换的pml4流程设置起来。

**2024年10月15日**

qemu命令：

info mem查看内存映射

**2024年10月29日**

为了能够方便地把外部编译好的程序直接搬到里面运行，也避免重定位，试着把OS移到高地址去运行。

所谓高地址，实际上就是让canonical address的高16位全为1，成为0xffff 0000 0000 0000的形式，这样自然就高地址了。

看了下canonical address的定义，高16位是一是零根据bit47位决定，与之相同，那么就是说，从零到0x0000 7fff ffff ffff这样子的地址都是规范的，而接下来的地址由于bit47=1，所以7fff ffff ffff的下一个地址其实是0xffff 8000 0000 0000。

本质上就是把内核放在了高一半的内存空间。

试了之后可以是可以的，但是这样子，会有以下问题：

1. grub引导的时候是保护模式，不能直接把内核加载到高地址；
2. 这样，elf里面的符号全都是低地址，跳转到高地址之后断电全部失效。

这样太不方便了……除非我不用grub，和《自己动手》那个人一样自己写引导，不然高地址很不方便……

实在不行的话，我就把内存空间分布反一反好了~内核占低一半，用户空间占高一半~

发现key_proc新bug：

ist推入的中断堆栈里面怎么rsp放的还是处于ist里面的范围？

想想应该是多重中断了。

发现在这之前还发生过general protect 和 page fault，排查后应该是之前的测试进程的原因。

 暂时将fork的测试放到后面吧。

**2024年10月30日**

经检查，键盘部分的字符获取其实没有问题，不知道为什么输出的时候总会多几个空格。

不过没问题的话，我就可以放心了。

之后为了更加符合POSIX规范，感觉要把STDIN这些东西开起来。

POSIX里面有提到两个设备：

1. /dev/console：控制台，仅一个，关联的操作主要是和实际设备操作有关
2. /dev/tty：虚拟控制台，每个session一个，操作基本是虚拟的

也就是说，实际的framebuffer部分操作应该是属于console，而进程操作的时候的read，write是对着tty的。

而tty是字符设备，负责将内容发送到console。

然后关于控制台还有：

几个进程组成一个进程组，几个进程组组成一个会话session。每个会话有一个controlling terminal（控制台），会话中有一个前台进程组，剩下的是后台进程组。只有前台进程组可以直接读写控制台。前台进程组的leader持有controlling terminal控制终端，其他的进程可能有别的终端，但是同一时间只能有一个控制终端，控制终端和会话一一对应。

一般来说，前台进程组创建子进程，等待其执行完毕，获得返回值，然后将内容写入控制台。

这么说，tty在进程创建的时候决定是否要配套创建，其自身要有一个缓冲区作为stdin等。然后，只有控制终端才会把缓冲区的内容输出到console中。



然后是进程的信号signal部分。可以通过signal(sig, func)设置某信号的处理函数，但是调用func之前都会先调用SGI_DFL的处理函数。

**2024年11月2日**

看了关于串口的开发教程，终于实现了串口通讯。

现在可以通过串口输出调试信息了，这样看起来更美观……



修改了vfs中的bug，把devman的/dev整合到了vfs里面，现在可以用系统调用操作/dev下的设备了 

而且仿照initrd设置了个rootfs，把实际的fat32挂载到了mnt下面！
